from numpy.core.fromnumeric import nonzero
import pytest

import os
from pathlib import Path
import shutil
import sys
import hashlib
from typing import Dict, Any
import re

import subprocess
import json

from scripts.installer.utils.purge_folders import delete_pycache_folders

# TODO: June 21/2025 -- This is a hack to get the test to run.
root = "/home/deeplearning/cx-field-tools-installer"
tfvars_path = f"{root}/terraform.tfvars"
tfvars_backup_path = f"{root}/terraform.tfvars.backup"
test_tfvars_path = f"{root}/tests/datafiles/terraform.tfvars"

# Cache infrastructure for `terraform plan` results.
_plan_cache: Dict[str, Any] = {}
_cache_dir = f"{root}/tests/.plan_cache"

override_file = f"{root}/override.auto.tfvars"
tfplan_file = f"{root}/tfplan"
tfplan_json_file = f"{root}/tfplan.json"

"""
EXPLANATION
=======================================
Originally tried using [tftest](https://pypi.org/project/tftest/) package to test but this became complicated and unwieldy. Instead, simplified
testing loop to:

1. Test in the project directory.
2. Take a backup of the existing `terraform.tfvars` file.
3. Create a new `terraform.tfvars` file for testing purposes (_sourced from `tests/datafiles/generate_core_data.sh`).
4. Provide override values to test fixtures (which will generate a new `override.auto.tfvars` file in the project root).
    This file supercedes the same keys defined in the `terraform.tfvars` file.
5. Run the tests:
    1. For each fixture, run `terraform plan` based on the test tvars and override file. Results as cached to speed up n+1 test runs.
    2. Execute tests tied to that fixture.
    3. Repeat.
6. Purge the test tfvars and override file.
7.Restore the original `terraform.tfvars` file when testing is complete.
"""


## ------------------------------------------------------------------------------------
## Cache Utility Functions
## ------------------------------------------------------------------------------------
def get_cache_key(override_data: str, qualifier: str = "") -> str:
    """Generate SHA-256 hash of override data and tfvars content for cache key."""
    normalized_override = override_data.strip()
    normalized_qualifier = qualifier.strip()

    # Read tfvars file content and include in cache key
    try:
        with open(tfvars_path, "r") as f:
            tfvars_content = f.read().strip()
    except FileNotFoundError as e:
        print(f"An error occurred: {e}")
        sys.exit(1)

    # Combine override data and tfvars content for cache key
    combined_content = f"{normalized_override}\n---TFVARS---\n{normalized_qualifier}\n---QUALIFIER---\n{tfvars_content}"
    return hashlib.sha256(combined_content.encode("utf-8")).hexdigest()[:16]


def strip_overide_whitespace(override_data: str) -> str:
    """Strip whitespace from override data.
    # Remove intermediate whitespace (extra space makes same keys hash to different values).
    # Convert multiple sapces to single space (ASSUMPTION: Python tabs insert spaces!)
    # NOTE: Need to keep `\n` to not break HCL formatting expectations.
    """
    return "\n".join(re.sub(r"\s+", " ", line) for line in override_data.splitlines())


def read_json(file_path: str) -> dict:
    """Read a JSON plan file."""
    with open(file_path, "r") as f:
        return json.load(f)


def read_file(file_path: str) -> str:
    """Read a file."""
    with open(file_path, "r") as f:
        return f.read()


def write_file(file_path: str, content: str | bytes) -> None:
    """Write content to a file."""
    with open(file_path, "w") as f:
        f.write(content)


def run_terraform_plan(qualifier: str = "") -> None:
    """
    Override file generated by prepare_plan; core tfvars file generated by fixture.
    Purge existing tfplan and tfplan.json.
    """
    for file in [f"{root}/tfplan", f"{root}/tfplan.json"]:
        Path(file).unlink(missing_ok=True)

    print("Generating tfplan.")
    command = f"terraform plan {qualifier} -out=tfplan" if len(qualifier) > 0 else f"terraform plan -out=tfplan"

    subprocess.run(
        command.split(" "),
        check=True,
        stdout=subprocess.DEVNULL,  # > /dev/null
        stderr=subprocess.STDOUT,  # 2>&1
    ).stdout


def convert_plan_to_json() -> None:
    print("Regenerating tfplan.json.")
    raw = subprocess.run(
        ["terraform", "show", "-json", "tfplan"],
        check=True,
        capture_output=True,
        text=True,
    ).stdout

    write_file(tfplan_json_file, json.dumps(json.loads(raw), indent=2))


def run_terraform_apply(qualifier: str = "", auto_approve: bool = True) -> None:
    """Run terraform plan.
    Override file generated by prepare_plan; core tfvars file generated by fixture.
    """
    if qualifier == "":
        print(f"Applying tfplan.")
        command = f"terraform apply {'--auto-approve' if auto_approve else ''} tfplan"
    else:
        # Should not normally need this, but adding just in case.
        print(f"Using {qualifier=} instead of tfplan.")
        command = (
            f"terraform apply {'--auto-approve' if auto_approve else ''} {qualifier}"
        )

    subprocess.run(
        command.split(" "),
        check=True,
        # stdout=subprocess.DEVNULL,  # > /dev/null
        stderr=subprocess.STDOUT,  # 2>&1
    )


## ------------------------------------------------------------------------------------
## Helpers
## ------------------------------------------------------------------------------------
def prepare_plan(
    override_data: str,
    qualifier: str = "",
    will_apply: bool = False,
    use_cache: bool = True,
) -> dict:
    """Generate override.auto.tfvars and run terraform plan with caching.

    Args:
        override_data: Terraform variable overrides
        qualifier: Additional modifier to add to cache key (e.g '-target=null_resource.my_resource')
        will_apply: Whether this plan will be chained into a Terraform apply (default: False)
        use_cache: Whether to use cached results (default: True)

    Returns:
        Terraform plan JSON data
    """

    override_data = strip_overide_whitespace(override_data)
    cache_key = get_cache_key(override_data, qualifier)
    cached_json_file = f"{_cache_dir}/plan_{cache_key}.json"

    # Seems impossible to save tfplan (deemed stale after apply).
    # Save the JSON for local, accept needing to run apply for remote.
    if use_cache and os.path.exists(cached_json_file) and not will_apply:
        # We need JSON rendering of plan only. Enough to copy key to root.
        print(f"Loading cached JSON plan from disk: {cache_key}")
        shutil.copy(cached_json_file, tfplan_json_file)

    else:
        if use_cache and os.path.exists(cached_json_file) and will_apply:
            # We need to regenerate the plan so it's not stale.
            # TODO: Maybe dont need to generate the plan since apply does it too. Can I get JSON output from apply?
            # TODO: Maybe I can keep plan if I use a fixture to clean up? TBD. What are impacts of a terraform delete after every test?
            print(f"Regenerating plan for: {cache_key}")
        else:
            # No cache hit. Treat as new plan.
            print(f"Cache miss. Generating new plan for: {cache_key}")

        # Make cachedir, write override file in root, make tfplan, copy tfplan to cachedir.
        os.makedirs(_cache_dir, exist_ok=True)
        write_file(override_file, override_data)

        import time

        time.sleep(10)

        run_terraform_plan(qualifier)
        convert_plan_to_json()

        shutil.copy(tfplan_json_file, cached_json_file)

    return read_json(tfplan_json_file)


def parse_key_value_file(file_path: str) -> Dict[str, str]:
    """Parse a file containing KEY=VALUE pairs.

    Args:
        file_path: Path to the file to parse

    Returns:
        Dictionary containing key-value pairs
    """
    result = {}

    try:
        with open(file_path, "r") as f:
            for line in f:
                line = line.strip()
                if line and "=" in line:
                    key, value = line.split("=", 1)
                    result[key.strip()] = value.strip()
    except FileNotFoundError:
        print(f"File not found: {file_path}")
    except Exception as e:
        print(f"Error parsing file {file_path}: {e}")

    return result
